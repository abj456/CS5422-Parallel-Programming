---
title: HW1 Odd-Even Sort

---

# HW1 Odd-Even Sort
> [name=蔡品棠, 112062525]
## Implementation
* How do you handle an arbitrary number of input items and processes?
    * 藉由計算`sendcounts[]`來更平均的分配compute workload，並且在input items小於process數量時，會因為自己的rank大於remind而使得`sendcounts[rank] = 0` (第12行)。
    ```cpp=
    int array_size = atoi(argv[1]);
    char *input_filename = argv[2];
    char *output_filename = argv[3];

    int base = array_size / total_ranks;
    int remind = array_size % total_ranks;
    used_ranks = (base == 0) ? remind : total_ranks;

    int sendcounts[total_ranks];
    int displs[total_ranks];
    for(int i = 0; i < total_ranks; i++) {
        sendcounts[i] = base + (i < remind ? 1 : 0);
        displs[i] = (i == 0) ? 0 : displs[i - 1] + sendcounts[i - 1];
    }
    int local_data_size = sendcounts[rank];
    float *local_data = new float[local_data_size];
    float *merged_data = new float[sendcounts[0] * 2];

    int max_recv_data_size = (rank > 0) ? sendcounts[rank - 1] : sendcounts[rank];
    float *recv_data = new float[max_recv_data_size];
    ```
* How do you sort in your program?
    * local sorting的部分，選用`boost::sort::spreadsort::spreadsort()`以達到最好的sorting performance。
    * 跨process之間的sorting則採用linear merge避免O(nlogn)的time complexity。
    * process會互相傳送自己sorting好的資料給對方後，各自做運算並取出自己需要的部分，藉以平衡運算loading。
* Other efforts you’ve made in your program.
    * 傳送資料前會先傳送頭尾的data給對方，確認兩邊data範圍是否有重複，若無重複則可略過不做merge。這樣可以避免無謂的*SendRecv()*。
    * linear merge的部分也會根據需要的部分不同，而只做前半或後半的merging，也是藉此省掉冗贅的合併。
    * 讀取與寫入使用`MPI_File_read_at()`和`MPI_File_write_at()`來設定每個process要存取的區段，藉此做到平行存取來提升IO的效率。
    * 會用到的data array或buffer都盡量事先做malloc，減少memory allocation。
    * process之間互相send和receive的過程改由`MPI_Sendrecv()`，減少waiting時間。
## Experiment & Analysis
### Methodology
* System Spec: 使用課程所提供的apollo cluster
* Performance Metrics: 使用nvtx來測量時間
    * communication time和IO time因為可以利用mpi event trace直接得到運行時間，這邊就單純做csv輸出
    * computing time則是在spreadsort前後，以及linear merge function的前後各加上`nvtxRangePush()`和`nvtxRangePop()`來得到。

### Speedup Factor & Profile
* Experimental Method
    * 我選擇testcases 40作為測資，資料量為536869888
    * 除了process數量24的configuration用了2 node、12 processes per node以外，皆只用1個node。
* Performance Measurement
    * profiler: nsys
    * basic metrics:
        * CPU time
        * Communication time
        * IO time
* Analysis of Results
    * ![time profile](https://hackmd.io/_uploads/H1VLf9GZkx.png)
    * ![speedup factor](https://hackmd.io/_uploads/SykPz9G-Jg.png)
* Optimization Strategies

### Discussion
* Compare I/O, CPU, Network performance. Which is/are the bottleneck(s)? Why? How could it be improved?
    * 在我所得到的實驗數據中，I/O反而是最大的瓶頸點，比Communication還要多。這點可以從nvtx分析出的數據繪製而成的圖表看到。
    * I/O數據可從MPI File相關的API得到，Communication time則從`MPI_Sendrecv()`取得。
    * 我認為若有額外時間可以取得單一process負責寫入所有資料的實驗數據，或許就能觀察出背後的瓶頸點會不會是在多個process使用`MPI_File_write_at()`的狀況下出現race condition。
* Compare scalability. Does your program scale well? Why or why not? How can you achieve better scalability? You may discuss the two implementations separately or together.
    * 我的程式效能在process數量超過8以後就沒有進一步提升。
    * 要進一步提升效能的話，我認為除了改善I/O的讀寫方式以外，硬體效能方面或許也是可以考慮的點。
        * 在qct server上面跑過同樣版本的hw1 code，發現runtime要比apollo快上至少25%。

## Experiences / Conclusion
* Your conclusion of this assignment. What have you learned from this assignment?
    * 重溫並鞏固對process的概念(與thread的不同之處、瓶頸點可能大不相同等等)
    * 對process-level的平行化來說，computing本身常常已經不是瓶頸點，更多的反而是在process之間或甚至node之間的溝通，以及I/O的處理上。
    * 也因此我們可以看到在process數量上升到一定程度後，得到的加速效果就已經式微；跨node後更是讓效能劇烈下降。
* What difficulties did you encounter in this assignment?
    * 由於是初次寫這種process之間需要互相溝通的程式，一開始對於如何平行化苦惱相當久。不過因為Odd-Even Sort作為平行程式課程的練習似乎相當經典，因此透過參考別人的寫法後學到很多基礎的概念。
    * 在linear merge上也思考許久，嘗試多種寫法但對於performance的提升都有限。直到開始寫report實際分析數據後才發現大多是卡在computing time以外的部分。

